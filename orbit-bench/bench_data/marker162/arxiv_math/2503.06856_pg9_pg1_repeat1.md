and this last expression is equal to the expectation in (3.4), from the definition of the process II( ) and the fact that T is F -- measurable.

Remark 3.2. The expectation in (3.4) is still well-defined for the infinite time horizon T = 0. Indeed, on the event {T < 0} this is obvious, while on the event {7 = 0} the expression is welldefined since the functions c;(;), i = 0,1 are defined on [0,7], while the process II(;) of (3.2) has a limit at infinity (by the Martingale Convergence Theorem).

The identity (3.4) and the fact that the processes X(.) and II(.) generate the same filtrations enable us to reinterpret the optimal stopping problem (2.9) as maximizing the expression (3.4) over all stopping times 7 of the filtration generated by the process II(-). To solve this problem, we embed it into a general Markovian framework allowing for arbitrary initial data (t, π).

## 3.1.1. General Markovian Framework

We fix a probability space (2, F, P), supporting a standard Brownian motion B = {B(t), 0 ≤ t < < >>. For each T E (0, 1], we consider a stochastic process II" = {IT(t), 0 < t < 0} with state space [0, 1], which satisfies

$$
\Pi^\pi(t) = \pi + \int\_0^t a \, \Pi^\pi(s) (1 - \Pi^\pi(s)) \, dB(s), \quad 0 \le t < \infty. \tag{3.5}
$$

The processes II" (.), n E [0, 1] mimic the conditional process (3.2) with arbitrary starting positions 7. For any T E [0,1], the Lipschitz property of the coefficients on [0,1] guarantees the existence and uniqueness of the strong solution to the equation (3.5) (see, e.g., Chapter 5.2.B in Karatzas & Shreve [30)). Moreover, the processes B(-) and IIT(-), n E (0, 1), generate the same filtration, as in the proof of Lemma 3.1. Hence, regardless of T, we let F = { + ( + > ( + > ( + = > ( + ) + = = = = = = = = = = = = filtration generated by the processes IT"(.) T E (0,1), i.e., we set F(t) := 7(B(s),0 < s < t). In addition, we denote by Tr the collection of all F-stopping times 7 such that P(r < T) = 1.

For fixed T E [0,1], time horizon T, and initial time t, we now consider the corresponding optimal stopping problem of maximizing the expected reward

$$J\_T(t, \pi, \tau) := \mathbb{E}\left[ \left( c\_1(t + \tau) \, \Pi^\pi(\tau) - c\_0(t + \tau) \left( 1 - \Pi^\pi(\tau) \right) \right)^+ \right] \tag{3.6}$$

over all stopping times T E Tr-t, where the functions c2 : [0,1] i = 0,1, satisfy the assumptions (A1)-(A5). We denote the gain function of this problem by

$$G(t,\pi) := \left(c\_1(t)\pi - c\_0(t)(1-\pi)\right)^+,\tag{3.7}$$

and its value function by

$$V\_T(t,\pi) \coloneqq \sup\_{\tau \in \mathcal{T}\_{T-t}} J\_T(t,\pi,\tau) = \sup\_{\tau \in \mathcal{T}\_{T-t}} \mathbb{E}[G(t+\tau,\Pi^\pi(\tau))].\tag{3.8}$$

Clearly, the original optimal stopping problem (2.9) can be embedded into the one above by setting m = p, t = 0. Therefore, if we find the value function V7( , ) of (3.8) and the corresponding optimal stopping time, we will automatically solve the original stopping problem as well. For some future arguments, it will be convenient to treat the processes II"(.), n e [0, 1] of the new