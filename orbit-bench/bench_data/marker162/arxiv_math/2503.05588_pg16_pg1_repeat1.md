that I is surjective. Suppose Z E L'(Y, t, d') so that ||Zn-Z||2 → 0 for some Zn E E(Y, t, d'). By isometry we conclude that Hn := IT-1(Zn) is a Cauchy sequence converging to some H & L'(X, t, d'). Finally |1+H - Z | = lim, >0 |Zn - 2 | = 0 and therefore I(H) = Z.

Equation (3.11) is evident in the case that y is a simple function. For general y ∈ L(X, d'), choose a sequence of simple y(1) with ||y(") -> 0. By (3.9) and Ito's isometry we have

$$\left\| \int\_{0}^{t} \chi^{\left[n\right]} (\mathsf{s}) \, \mathrm{d}X(\mathsf{s}) - \int\_{0}^{t} \chi(\mathsf{s}) \, \mathrm{d}X(\mathsf{s}) \right\|\_{2} \to 0, \qquad \left\| \int\_{0}^{t} \chi^{\left[n\right]}(\mathsf{s}) \, \mathrm{d}Y(\mathsf{s}) - \int\_{0}^{t} \chi(\mathsf{s}) \, \mathrm{d}Y(\mathsf{s}) \right\|\_{2} \to 0$$

as n -> ∞. The claim then follows because the continuity of the operator I, yields

$$I\_t \int\_0^t \chi(\mathbf{s}) \, \mathrm{d}X(\mathbf{s}) = \lim\_{n \to \infty} I\_t \int\_0^t \chi^{(n)}(\mathbf{s}) \, \mathrm{d}X(\mathbf{s}) = \lim\_{n \to \infty} \int\_0^t \chi^{(n)}(\mathbf{s}) \, \mathrm{d}Y(\mathbf{s}) = \int\_0^t \chi(\mathbf{s}) \, \mathrm{d}Y(\mathbf{s}). \quad \Box$$

## 4 Filtering, smoothing, and prediction

This section is devoted to optimal linear filtering, prediction and smoothing of partially observed polynomial processes. We let either I := N or I := R, and fix a probability space (2, 9, (Ft)ter, P) as well as an R4-valued adapted process X = (X(t))ter. If I = R+, we assume (Fr)ter to be right-continuous. Suppose that the components Xm+(t), ... , Xa(t) are observable whereas X(t), ... , Xm(t) are not. We let the subscript o stand for the observable part of a vector x € Rd and let H := (8m+i,ji=1,...d-m;=1,...d, i.e. xo == (xm+1, ... , xa). For Σ E R4xd we set Σ.,ο := ΣΗ = Σι.α,m+1:d, Σο; := ΗΣ = Σm+1:d,1:d as well ας Σο := ΗΣΗΤ = Σπ+1:α, π+1:d, Πα subscript u standing for the unobservable part of a vector is treated in the same manner.

We suppose that E(|X(t)|2) < ∞ for t ∈ I and consider the following general filtering problem for fixed t ∈ I. The goal is to minimise the mean square error E(〖X(t) – Y[^) over all random variables Y that are measurable with respect to the observable information

$$\mathcal{H}\_t := \sigma\big(\left\{X\_0(\mathbf{s}) : \mathbf{s} \in I, \; \mathbf{s} \le t\right\}\big). \tag{4.1}$$

We call the minimiser of (4.1) the optimal filter for X. Regardless of any specific model the optimal filter is then given by the conditional mean X(t,t) := E(X(t)(9).

## 4.1 Discrete-time linear filtering problems

Let I = IN. For Gaussian state space models, the optimal filter can be computed recursively:

Proposition 4.1 (Kálmán filter). Suppose that X is a linear Gaussian state space model as in Definition 3.1 and set C(t) := B(t)B(t) . Let X(0,-1) := E(X(0)), Σ(0,-1) := Cov(X(0)) and

$$\begin{aligned} \hat{X}(t+1,t) &:= a(t+1) + A(t+1)\hat{X}(t,t), \\ \hat{X}(t,t) &:= \widehat{X}(t,t-1) + \widehat{\Sigma}\_{:,\mathrm{o}}(t,t-1)\widehat{\Sigma}\_{\mathrm{o}}(t,t-1)^{+} \left(X\_{\mathrm{o}}(t) - \widehat{X}\_{\mathrm{o}}(t,t-1)\right), \\ \widehat{\Sigma}(t+1,t) &:= A(t+1)\widehat{\Sigma}(t,t)A(t+1)^{\top} + C(t+1), \\ \widehat{\Sigma}(t,t) &:= \widehat{\Sigma}(t,t-1) - \widehat{\Sigma}\_{:,\mathrm{o}}(t,t-1)\widehat{\Sigma}\_{\mathrm{o}}(t,t-1)^{+}\widehat{\Sigma}\_{\mathrm{o},\mathrm{i}}(t,t-1) \end{aligned}$$