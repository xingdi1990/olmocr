define the set $S \subseteq \{ 1 , 2 , . . . , n \} \times \{ 1 , 2 , . . . , f + g \}$ , and assume the entry $\Big [ A _ { \mathrm { t r u e } } \ B _ { \mathrm { t r u e } } \Big ] _ { i j }$ is given for all $( i , j ) \in S$ . The set of systems compatible with the prior knowledge is given by  

$$
\begin{array} { r l } & { \Sigma _ { p k } ( S ) : = \Big \{ ( A , B ) \ | } \\ & { \qquad \Big [ A \ B \Big ] _ { i j } = \Big [ A _ { \mathrm { t r u e } } \ B _ { \mathrm { t r u e } } \Big ] _ { i j } \forall ( i , j ) \in S \Big \} . } \end{array}
$$  

Subsequently, we define the set of systems compatible with both the data and the prior knowledge as  

$$
\Sigma : = \Sigma _ { d } \cap \Sigma _ { p k } ( S ) .
$$  

Note that the case that all entries of $A _ { \mathrm { t r u e } }$ and $B _ { \mathrm { t r u e } }$ are unknown can be captured by setting $S = \emptyset$ , which implies $\Sigma = \Sigma _ { d }$ . It is clear from (2) and (6) that the system $( A _ { \mathrm { t r u e } } , B _ { \mathrm { t r u e } } )$ belongs to $\Sigma$ . However, in general, $\Sigma$ contains other systems because the data may not uniquely determine $A _ { \mathrm { t r u e } }$ and $B _ { \mathrm { t r u e } }$ , even if some entries of $A _ { \mathrm { t r u e } }$ and $B _ { \mathrm { t r u e } }$ are known.  

The goal of this paper is to find a controller that stabilizes the origin of the system $( A _ { \mathrm { t r u e } } , B _ { \mathrm { t r u e } } )$ . Since on the basis of the data and the prior knowledge we cannot distinguish between $( A _ { \mathrm { t r u e } } , B _ { \mathrm { t r u e } } )$ and any other system in $\Sigma$ , we need to find a single controller that stabilizes the origin of all systems in $\Sigma$ . This motivates the following definition of informative data for stabilization of polynomial systems. In the rest of the paper, we assume that  

$$
F ( 0 ) = 0 .
$$  

Definition 1 The data $( \dot { \mathcal { X } } , \mathcal { X } , \mathcal { U } )$ are called informative for stabilization if there exist a radially unbounded function $V \in \mathcal V$ and a continuous controller $K : \mathbb { R } ^ { n }  \mathbb { R } ^ { m }$ such that $K ( 0 ) = 0$ and  

$$
\frac { \partial V ( \boldsymbol { x } ) } { \partial \boldsymbol { x } } ( A F ( \boldsymbol { x } ) + B G ( \boldsymbol { x } ) K ( \boldsymbol { x } ) ) < 0 \quad \forall \boldsymbol { x } \in \mathbb { R } ^ { n } \backslash \{ \boldsymbol { 0 } \} ,
$$  

for all $( A , B ) \in \Sigma$ .  

Note that for a controller $K$ satisfying $K ( 0 ) = 0$ , the origin of the closed-loop system  

$$
\dot { x } = A F ( x ) + B G ( x ) K ( x ) ,
$$  

is an equilibrium point, as $F ( 0 ) = 0$ . If (8) holds then the origin is globally asymptotically stable for all closedloop systems obtained by interconnecting any system $( A , B ) \in \Sigma$ with the controller $u = K ( x )$ .  

In this paper, we study the following two problems.  

Problem 1 (Informativity) Find conditions under which the data $( \dot { \mathcal { X } } , \mathcal { X } , \mathcal { U } )$ are informative for stabilization.  

Problem 2 (Controller design) Suppose the data $( \dot { \mathcal { X } } , \mathcal { X } , \mathcal { U } )$ are informative for stabilization. Find a controller $u = K ( x )$ satisfying $K ( 0 ) = 0$ and (8).  

# 3 Connection to previous work  

Current approaches for data-driven control of polynomial systems [8,9] build on the model-based method proposed in [15]. These methods do not incorporate prior knowledge and instead focus on designing a common stabilizing controller for all systems compatible with the data. In these works, the controller is considered to be of the form  

$$
K ( x ) = Y ( x ) P Z ( x ) ,
$$  

where $Y \in \mathbb { R } ^ { m \times p } [ x ]$ , $P \in \mathbb { S } ^ { p }$ is positive definite, and $Z \in \mathbb { R } ^ { p } [ x ]$ is radially unbounded satisfying  

$$
F ( x ) = H ( x ) Z ( x ) ,
$$  

for some $H \in \mathbb { R } ^ { f \times p } [ x ]$ . The choice of candidate Lyapunov function  

$$
V ( x ) = Z ^ { \top } ( x ) P Z ( x ) ,
$$  

then leads to  

$$
\frac { \partial V } { \partial x } ( x ) ( A F ( x ) + B G ( x ) K ( x ) ) = 2 Z ^ { \top } ( x ) P \Theta ( x ) P Z ( x ) ,
$$  

where  

$$
\Theta ( x ) : = \frac { \partial Z } { \partial x } ( x ) \left[ A \ B \right] \left[ H ( x ) P ^ { - 1 } \right] .
$$  

The main idea in this line of work is to find $P$ and $Y ( x )$ such that  

$$
- \Theta ( x ) - \Theta ^ { \top } ( x ) > 0 \quad \forall x \in \mathbb { R } ^ { n } \setminus \{ 0 \} ,
$$  

for all systems $( A , B )$ compatible with the data. In the earlier work [8], $H ( x )$ is taken to be equal to the identity matrix, which implies that $Z ( x ) = F ( x )$ . In contrast, [9] considers more general $Z ( x )$ satisfying (10). This strategy is appealing because it leads to data-based linear matrix inequalities for control design. Unfortunately, however, the method also has some major limitations.  

(1) The matrix $\textstyle { \frac { \partial Z } { \partial x } } ( x )$ must have full row rank for all $x \in \mathbb { R } ^ { n } \setminus \{ 0 \}$ .  

Indeed, suppose that there exists a nonzero $x$ such that $\textstyle { \frac { \partial Z } { \partial x } } ( x )$ does not have full row rank. Then $\Theta ( x )$ is singular, which implies that (12) does not hold. Note that the full row rank condition can only hold if $p \leq n$ , i.e., the number of polynomials in $Z$ is less than or equal to the state-space dimension of the system. This limits the class of Lyapunov functions of the form (11) that can be considered by the  