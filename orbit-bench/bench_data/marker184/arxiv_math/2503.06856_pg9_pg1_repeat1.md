and this last expression is equal to the expectation in (3.4), from the definition of the process  $\Pi(\cdot)$ and the fact that  $\tau$  is  $\mathcal{F}_{\tau}$ -measurable.

**Remark 3.2.** The expectation in (3.4) is still well-defined for the infinite time horizon  $T = \infty$ . Indeed, on the event  $\{\tau < \infty\}$  this is obvious, while on the event  $\{\tau = \infty\}$  the expression is welldefined since the functions  $c_i(\cdot), i = 0, 1$  are defined on  $[0, T]$ , while the process  $\Pi(\cdot)$  of (3.2) has a limit at infinity (by the Martingale Convergence Theorem).

The identity (3.4) and the fact that the processes  $X(\cdot)$  and  $\Pi(\cdot)$  generate the same filtrations enable us to reinterpret the optimal stopping problem  $(2.9)$  as maximizing the expression  $(3.4)$  over all stopping times  $\tau$  of the filtration generated by the process  $\Pi(\cdot)$ . To solve this problem, we embed it into a general Markovian framework allowing for arbitrary initial data  $(t, \pi)$ .

## $3.1.1.$ General Markovian Framework

We fix a probability space  $(\Omega, \mathcal{F}, \mathbb{P})$ , supporting a standard Brownian motion  $B = \{B(t), 0 \leq$  $t < \infty$ . For each  $\pi \in [0,1]$ , we consider a stochastic process  $\Pi^{\pi} = \{\Pi^{\pi}(t), 0 \leq t < \infty\}$  with state space  $[0, 1]$ , which satisfies

$$\Pi^{\pi}(t) = \pi + \int_{0}^{t} a \, \Pi^{\pi}(s) (1 - \Pi^{\pi}(s)) \, dB(s), \quad 0 \leqslant t < \infty. \tag{3.5}$$

The processes  $\Pi^{\pi}(\cdot)$ ,  $\pi \in [0,1]$  mimic the conditional process (3.2) with arbitrary starting positions  $\pi$ . For any  $\pi \in [0,1]$ , the Lipschitz property of the coefficients on [0,1] guarantees the existence and uniqueness of the strong solution to the equation  $(3.5)$  (see, e.g., Chapter 5.2.B in Karatzas & Shreve [30]. Moreover, the processes  $B(\cdot)$  and  $\Pi^{\pi}(\cdot), \pi \in (0,1)$ , generate the same filtration, as in the proof of Lemma 3.1. Hence, regardless of  $\pi$ , we let  $\mathbb{F} := \{\mathcal{F}(t)\}_{t\geq 0}$  be the augmentation of the filtration generated by the processes  $\Pi^{\pi}(\cdot)$   $\pi \in (0,1)$ , i.e., we set  $\mathcal{F}(t) := \overline{\sigma}(B(s), 0 \leq s \leq t)$ . In addition, we denote by  $\mathcal{T}_T$  the collection of all  $\mathbb{F}$ -stopping times  $\tau$  such that  $\mathbb{P}(\tau \leq T) = 1$ .

For fixed  $\pi \in [0,1]$ , time horizon T, and initial time t, we now consider the corresponding optimal stopping problem of maximizing the expected reward

$$J_T(t,\pi,\tau) := \mathbb{E}\left[\left(c_1(t+\tau)\,\Pi^{\pi}(\tau) - c_0(t+\tau)\,(1-\Pi^{\pi}(\tau))\right)^+\right] \tag{3.6}$$

over all stopping times  $\tau \in \mathcal{T}_{T-t}$ , where the functions  $c_i : [0,T] \to [0,1], i = 0,1$ , satisfy the assumptions  $(A1)$ â€“ $(A5)$ . We denote the gain function of this problem by

$$G(t,\pi) := \left(c_1(t)\pi - c_0(t)(1-\pi)\right)^+, \tag{3.7}$$

and its value function by

$$V_T(t,\pi) := \sup_{\tau \in \mathcal{T}_{T-t}} J_T(t,\pi,\tau) = \sup_{\tau \in \mathcal{T}_{T-t}} \mathbb{E}\big[G\big(t+\tau,\Pi^{\pi}(\tau)\big)\big].\tag{3.8}$$

Clearly, the original optimal stopping problem  $(2.9)$  can be embedded into the one above by setting  $\pi = p, t = 0$ . Therefore, if we find the value function  $V_T(\cdot, \cdot)$  of (3.8) and the corresponding optimal stopping time, we will automatically solve the original optimal stopping problem as well. For some future arguments, it will be convenient to treat the processes  $\Pi^{\pi}(\cdot), \pi \in [0,1]$  of the new