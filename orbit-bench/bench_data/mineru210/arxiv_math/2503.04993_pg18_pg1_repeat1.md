Thus, the necessary optimality condition for a two-player game provides the conditions under which both players’ controls are optimal in response to each other’s strategies. Each player’s control must satisfy the condition that the derivative of the Hamiltonian with respect to their control vanishes almost everywhere, ensuring that the strategy of each player is optimal given the strategy of the other player.

Proof. Consider the variation of the functional $J _ { 1 }$ with respect to the control $u _ { 1 }$ . We compute the derivative:

$$
\frac { d } { d \epsilon } J _ { 1 } ( u _ { 1 } + \epsilon v _ { 1 } , u _ { 2 } ) \Big | _ { \epsilon = 0 } .
$$

Expanding the objective functional:

$$
\begin{array} { c } { { \displaystyle \frac { d } { d \epsilon } J _ { 1 } ( u _ { 1 } + \epsilon v _ { 1 } , u _ { 2 } ) \Big | _ { \epsilon = 0 } = \operatorname* { l i m } _ { \epsilon  0 } \frac { 1 } { \epsilon } \mathbb { E } \Bigg [ \int _ { R _ { Z } } \Big \{ f _ { 1 } ( \zeta , Y ^ { ( u _ { 1 } + \epsilon v _ { 1 } , u _ { 2 } ) } ( \zeta ) , u _ { 1 } ( \zeta ) + \epsilon v _ { 1 } ( \zeta ) , u _ { 2 } ( \zeta ) ) } } \\ { { - f _ { 1 } ( \zeta , Y ^ { ( u _ { 1 } , u _ { 2 } ) } ( \zeta ) , u _ { 1 } ( \zeta ) , u _ { 2 } ( \zeta ) ) \Big \} d \zeta + g _ { 1 } ( Y ^ { ( u _ { 1 } + \epsilon v _ { 1 } , u _ { 2 } ) } ( Z ) ) - g _ { 1 } ( Y ^ { ( u _ { 1 } , u _ { 2 } ) } ( Z ) ) \Bigg ] . } } \end{array}
$$

Using the first-order expansion:

$$
\begin{array} { l } { \displaystyle _ { 1 } ( u _ { 1 } + \epsilon v _ { 1 } , u _ { 2 } ) \Big | _ { \epsilon = 0 } = \mathbb { E } \Bigg [ \int _ { R _ { Z } } \Big \{ \frac { \partial f _ { 1 } } { \partial y } ( \zeta , Y ^ { ( u _ { 1 } , u _ { 2 } ) } ( \zeta ) , u _ { 1 } ( \zeta ) , u _ { 2 } ( \zeta ) ) G _ { 1 } ( \zeta ) } \\ { \displaystyle ~ + \frac { \partial f _ { 1 } } { \partial u _ { 1 } } ( \zeta , Y ^ { ( u _ { 1 } , u _ { 2 } ) } ( \zeta ) , u _ { 1 } ( \zeta ) , u _ { 2 } ( \zeta ) ) v _ { 1 } ( \zeta ) \Big \} d \zeta + \frac { \partial g _ { 1 } } { \partial y } ( Y ^ { ( u _ { 1 } , u _ { 2 } ) } ( Z ) ) G _ { 1 } ( \zeta , \zeta ) \Bigg ] , } \end{array}
$$

where $G _ { 1 }$ is the variation in the system’s state due to the change in control. We now decompose it into two terms:

$$
\frac { d } { d \epsilon } J _ { 1 } ( u _ { 1 } + \epsilon v _ { 1 } , u _ { 2 } ) \Big | _ { \epsilon = 0 } = I _ { 1 } + I _ { 2 } ,
$$

where

$$
\begin{array} { r l } & { I _ { 1 } = \mathbb { E } \Bigg [ \int _ { R _ { Z } } \Big ( \displaystyle \frac { \partial H _ { 1 } } { \partial y } ( \zeta ) - \displaystyle \frac { \partial \alpha } { \partial y } ( \zeta ) p _ { 1 } ( \zeta ) - \displaystyle \frac { \partial \beta } { \partial y } ( \zeta ) q _ { 1 } ( \zeta ) - ( L _ { 1 } \star \displaystyle \frac { \partial \alpha } { \partial y } ) ( \zeta ) \Big ) G _ { 1 } ( \zeta ) d \zeta } \\ & { \quad \quad \quad \quad + \int _ { R _ { Z } } \Big ( \displaystyle \frac { \partial H _ { 1 } } { \partial u _ { 1 } } ( \zeta ) - \displaystyle \frac { \partial \alpha } { \partial u _ { 1 } } ( \zeta ) p _ { 1 } ( \zeta ) - \displaystyle \frac { \partial \beta } { \partial u _ { 1 } } ( \zeta ) q _ { 1 } ( \zeta ) - ( L _ { 1 } \star \displaystyle \frac { \partial \alpha } { \partial u _ { 1 } } ) ( \zeta ) \Big ) v _ { 1 } ( \zeta ) d \zeta \Bigg ] , } \end{array}
$$