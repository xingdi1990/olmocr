and this last expression is equal to the expectation in (3.4), from the definition of the process $\Pi ( \cdot )$ and the fact that $\tau$ is $\mathcal { F } _ { \tau }$ –measurable.

Remark 3.2. The expectation in (3.4) is still well-defined for the infinite time horizon $T = \infty$ . Indeed, on the event $\{ \tau < \infty \}$ this is obvious, while on the event $\{ \tau = \infty \}$ the expression is welldefined since the functions $c _ { i } ( \cdot )$ , $i = 0 , 1$ are defined on $[ 0 , T ]$ , while the process $\Pi ( \cdot )$ of (3.2) has a limit at infinity (by the Martingale Convergence Theorem).

The identity (3.4) and the fact that the processes $X ( \cdot )$ and $\Pi ( \cdot )$ generate the same filtrations enable us to reinterpret the optimal stopping problem (2.9) as maximizing the expression (3.4) over all stopping times $\tau$ of the filtration generated by the process $\Pi ( \cdot )$ . To solve this problem, we embed it into a general Markovian framework allowing for arbitrary initial data $( t , \pi )$ .

# 3.1.1. General Markovian Framework

We fix a probability space $( \Omega , \mathcal { F } , \mathbb { P } )$ , supporting a standard Brownian motion $B = \{ B ( t ) , 0 \leqslant$ $t < \infty \}$ . For each $\pi \in [ 0 , 1 ]$ , we consider a stochastic process $\Pi ^ { \pi } = \{ \Pi ^ { \pi } ( t ) , 0 \leqslant t < \infty \}$ with state space $[ 0 , 1 ]$ , which satisfies

$$
\Pi ^ { \pi } ( t ) = \pi + \int _ { 0 } ^ { t } a \Pi ^ { \pi } ( s ) ( 1 - \Pi ^ { \pi } ( s ) ) d B ( s ) , \quad 0 \leqslant t < \infty .
$$

The processes $\Pi ^ { \pi } ( \cdot )$ , $\pi \in \left[ 0 , 1 \right]$ mimic the conditional process (3.2) with arbitrary starting positions $\pi$ . For any $\pi \in [ 0 , 1 ]$ , the Lipschitz property of the coefficients on $[ 0 , 1 ]$ guarantees the existence and uniqueness of the strong solution to the equation (3.5) (see, e.g., Chapter 5.2.B in Karatzas $\&$ Shreve [30]). Moreover, the processes $B ( \cdot )$ and $\Pi ^ { \pi } ( \cdot )$ , $\pi \in ( 0 , 1 )$ , generate the same filtration, as in the proof of Lemma 3.1. Hence, regardless of $\pi$ , we let $\mathbb { F } : = \{ \mathcal { F } ( t ) \} _ { t \geq 0 }$ be the augmentation of the filtration generated by the processes $\Pi ^ { \pi } ( \cdot )$ $\pi \in ( 0 , 1 )$ , i.e., we set ${ \mathcal { F } } ( t ) : = { \overline { { \sigma } } } ( B ( s ) , 0 \leqslant s \leqslant t )$ . In addition, we denote by $\mathcal { T } _ { T }$ the collection of all $\mathbb { F }$ –stopping times $\tau$ such that $\mathbb { P } ( \tau \leqslant T ) = 1$ .

For fixed $\pi \in [ 0 , 1 ]$ , time horizon $T$ , and initial time $t$ , we now consider the corresponding optimal stopping problem of maximizing the expected reward

$$
\begin{array} { r } { J _ { T } ( t , \pi , \tau ) : = \mathbb { E } \left[ \left( c _ { 1 } ( t + \tau ) \Pi ^ { \pi } ( \tau ) - c _ { 0 } ( t + \tau ) \left( 1 - \Pi ^ { \pi } ( \tau ) \right) \right) ^ { + } \right] } \end{array}
$$

over all stopping times $\tau \in \mathcal { T } _ { T - t }$ , where the functions $c _ { i } : [ 0 , T ]  [ 0 , 1 ] , i = 0 , 1$ , satisfy the assumptions (A1)–(A5). We denote the gain function of this problem by

$$
G ( t , \pi ) : = \big ( c _ { 1 } ( t ) \pi - c _ { 0 } ( t ) ( 1 - \pi ) \big ) ^ { + } ,
$$

and its value function by

$$
V _ { T } ( t , \pi ) : = \operatorname* { s u p } _ { \tau \in \mathcal { T } _ { T - t } } J _ { T } ( t , \pi , \tau ) = \operatorname* { s u p } _ { \tau \in \mathcal { T } _ { T - t } } \mathbb { E } \big [ G \big ( t + \tau , \Pi ^ { \pi } ( \tau ) \big ) \big ] .
$$

Clearly, the original optimal stopping problem (2.9) can be embedded into the one above by setting $\pi = p$ , $t = 0$ . Therefore, if we find the value function $V _ { T } ( \cdot , \cdot )$ of (3.8) and the corresponding optimal stopping time, we will automatically solve the original optimal stopping problem as well. For some future arguments, it will be convenient to treat the processes $\Pi ^ { \pi } ( \cdot )$ , $\pi \in [ 0 , 1 ]$ of the new